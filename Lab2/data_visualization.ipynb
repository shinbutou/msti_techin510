{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZGlGoIO-pNr"
   },
   "source": [
    "# LAB2: DATA VISUALIZATION & PROCESSING IN PYTHON\n",
    "In this lab you will practice Python data processing and visualization.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqeMmXmy_Ky1"
   },
   "source": [
    "## Step 1: Access the datasets\n",
    "\n",
    "You can access the data files for `Lab_2` on Canvas in the `Files/Lab 2` section of *TECHIN 510*, and then upload them to your local Jupyter server.\n",
    "* Robot Faces data set\n",
    "* People\n",
    "* Pre-recorded accelerometer data\n",
    "\n",
    "And you can incorporate them into your code using the sample code in the next cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LheiuPmvByaL"
   },
   "outputs": [],
   "source": [
    "## SAMPLE CODE\n",
    "import pandas as pd\n",
    "\n",
    "f1 = 'robot_faces.csv'\n",
    "f2 = 'people.csv'\n",
    "f3 = 'accelerometer.csv'\n",
    "\n",
    "faces = pd.read_csv(f1)\n",
    "people = pd.read_csv(f2)\n",
    "accel = pd.read_csv(f3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54ZlkTof_M4R"
   },
   "source": [
    "## Step 2: Robot face data exploration\n",
    "\n",
    "Let's start by exploring the data in `robot_faces.csv`. First, write the code for loading and preprocessing the data. After inspecting the different column names to better understand what the data includes, pose a specific question and write new code to answer that question. Some example questions are:\n",
    "* How many robots both have a mouth and a nose?\n",
    "* Which country has the highest fraction of robots with black face color?\n",
    "* Do more robots built after 2012 have blue eyes than those built before?\n",
    "\n",
    "Your code should print the question at the beginning and print the computed answer at the end. Your script should also create at least one visualization that allows a human to answer the same question without having to do calculations.\n",
    "\n",
    "*If you are interested, you can read more about the face data [here](https://spectrum.ieee.org/automaton/robotics/humanoids/what-people-see-in-157-robot-faces).* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9iqMQnQT_0-i"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do more robots built from 2015 on have white eyes than those built before? Yes, proportionally\n"
     ]
    }
   ],
   "source": [
    "## TODO: Write code to ask a question about the face data and answer it both visually and programmatically\n",
    "question = 'Do more robots built from 2015 on have white eyes than those built before?'\n",
    "\n",
    "previous_years = list(range(2001, 2015))\n",
    "previous_years.remove(2002)\n",
    "previous_years = list(map(str, previous_years))\n",
    "\n",
    "before = faces[faces['year'].isin(previous_years) == True]\n",
    "after = faces[faces['year'].isin(previous_years) == False]\n",
    "\n",
    "before_rate = len(before[before['eye color'] == 'white']) / len(before)\n",
    "after_rate = len(after[after['eye color'] == 'white']) / len(after)\n",
    "\n",
    "if before_rate == after_rate:\n",
    "    answer = 'As many proportionally.'\n",
    "elif before_rate < after_rate:\n",
    "    answer = 'No, proportionally'\n",
    "elif before_rate > after_rate:\n",
    "    answer = 'Yes, proportionally'\n",
    "\n",
    "print(f\"{question} {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization comparing the two statistics \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(['Before 2015', '2015 Onwards'], [before_rate, after_rate])\n",
    "plt.ylabel('Percentage')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>robot type</th>\n",
       "      <th>category</th>\n",
       "      <th>full head</th>\n",
       "      <th>screen type</th>\n",
       "      <th>mouth</th>\n",
       "      <th>nose</th>\n",
       "      <th>eyebrows</th>\n",
       "      <th>cheeks (blush)</th>\n",
       "      <th>...</th>\n",
       "      <th>eyebrow length</th>\n",
       "      <th>eyebrow arch</th>\n",
       "      <th>cheek color</th>\n",
       "      <th>cheek shape</th>\n",
       "      <th>cheek size</th>\n",
       "      <th>cheek placement</th>\n",
       "      <th>cheek spacing</th>\n",
       "      <th>hair color</th>\n",
       "      <th>country/region of origin</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Shanghai Jinghong</td>\n",
       "      <td>25</td>\n",
       "      <td>humanoid</td>\n",
       "      <td>service</td>\n",
       "      <td>x</td>\n",
       "      <td>blcd</td>\n",
       "      <td>y</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>...</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>pink</td>\n",
       "      <td>oval</td>\n",
       "      <td>med</td>\n",
       "      <td>up</td>\n",
       "      <td>wide</td>\n",
       "      <td>x</td>\n",
       "      <td>China</td>\n",
       "      <td>no data</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name  Unnamed: 1 robot type category full head screen type  \\\n",
       "26  Shanghai Jinghong          25   humanoid  service         x        blcd   \n",
       "\n",
       "   mouth nose eyebrows cheeks (blush)  ... eyebrow length eyebrow arch  \\\n",
       "26     y    x        x              y  ...              x            x   \n",
       "\n",
       "   cheek color cheek shape cheek size cheek placement cheek spacing  \\\n",
       "26        pink        oval        med              up          wide   \n",
       "\n",
       "   hair color country/region of origin     year  \n",
       "26          x                    China  no data  \n",
       "\n",
       "[1 rows x 77 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that there is one robot that does not have the year data, but it does not effect the overall result\n",
    "faces[faces['year'] == 'no data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54ZlkTof_M4R"
   },
   "source": [
    "## Step 3: Persons data exploration\n",
    "\n",
    "We continue our exploration of the data by diving into a dataset of notional (100% fake) persons. Just as you did with the Robot data, write the code for loading and preprocessing the Person data. After inspecting the different column names to better understand what the data includes, pose a specific question and write new code to answer that question. Some example questions are:\n",
    "* How many males are in the data set vs females?\n",
    "* Who are the oldest people living in Chicago?\n",
    "* Which city is most popular with people in their 30's?\n",
    "* What are the top 5 US states represented in the data?\n",
    "\n",
    "Your code should print the question at the beginning and print the computed answer at the end. Your script should also create at least one visualization that allows a human to answer the same question without having to do calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9iqMQnQT_0-i"
   },
   "outputs": [],
   "source": [
    "## TODO: Write code to ask a question about the person data and answer it both visually and programmatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6QdkSxgKACqR"
   },
   "source": [
    "## Step 4: Load and visualize accelerometer data\n",
    "\n",
    "Next you will explore the accelerometer data in `accelerometer.csv` recorded from a mobile device. \n",
    "\n",
    "The first thing your Python script should do is open the data file and parse its content into Python lists or arrays. Each row in the data file corresponds to one reading. The first value is the time in seconds, and the next three values are the x, y, z acceleration values from a mobile device accelerometer. Your goal for this part of the lab is to obtain four lists or arrays (of same length) each containing the different columns in the data file.\n",
    "\n",
    "You can use the `pd.read_csv()`, but if you would like to practice some of the string operations we used during the `chatbot` exercise last week, you can open the file, read its content into a single string, and then use the split() function to split into lines (`data_string.split(\"\\n\")`) and elements (`data_string.split(\",\")`).\n",
    "\n",
    "Before starting to process the data, visualize it to get a better sense of what is in the data. Keep visualization steps in your script for your lab submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oR389VvaASoo"
   },
   "outputs": [],
   "source": [
    "## TODO: Code for loading and visualizing accelerometer data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JD-CEhvkAaRI"
   },
   "source": [
    "## Step 5: Detecting lack of movement\n",
    "\n",
    "As a first data processing exercise, iterate over the lists or arrays you created to compute the: 1) total amount of time; and 2) percentage of time during which the person holding the mobile device was not moving (e.g., absolute acceleration smaller than ~0.2m/sec^2). Visualize parts of the data where lack of movement is detected together with the original data to verify that it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxuaPlLOAfKF"
   },
   "outputs": [],
   "source": [
    "## TODO: Code for detecting lack of movement (will be run after running code from Step 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfgBr8JnAmau"
   },
   "source": [
    "## Step 6: Counting steps\n",
    "\n",
    "Next you will iterate over the data to count how many steps were taken. There are alternative ways to do that but here we will outline an approximation of the \"zero-crossing\" method. Walking with an accelerometer results in cyclic patterns characterized by pairs of peaks and valleys in acceleration in some directions. In the provided data you can focus on the z dimension, since the mobile device was held in fixed orientation. To determine the peaks and valleys, iterate over the z values; compare each element in the list to the value of the previous and the next element (note that you cannot do this for the first and last elements of the list); if it is greater than or smaller than both of those, it corresponds to a peak or a valley. Create a separate list, of same length as the data lists, that has the value +1 where peaks occur, -1 where valleys occur, and 0 otherwise. Visualize the peaks and the valleys on the same plot as your data to verify that your algorithm works correctly.\n",
    "\n",
    "You will see that even very small variations in acceleration cause peaks and valleys, so we need to be stricter in detecting peaks and valleys that correspond to an actual step. For that, you can extend the condition for peaks and valleys to include a threshold on the absolute value (`math.fabs()`) of the acceleration in the z direction (e.g., ~1m/sec^2). Visually inspect the number of peaks and valleys with this stricter criteria. \n",
    "\n",
    "A rough approximation of the number of steps would be the `math.min()` of the numbers of peaks and number of valleys. If you are out of time for this lab, you can stop here. However, to count pairs of peaks and valleys more strictly, you need to iterate over the list of peaks and valleys to determine the number of times a peak is followed by a valley (or vice versa) within one second or so (i.e., -1 and 1 separated by no more than four 0s in the peak/valley list). So if you have time, implement counting of pairs as a more accurate approximation of the number of steps. \n",
    "\n",
    "Your script should print the counted number of steps on the terminal at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiNgcVNuAvC2"
   },
   "outputs": [],
   "source": [
    "## TODO: Code for counting steps in accelerometer data (will be run after Step 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yBHpypuhA7rx"
   },
   "source": [
    "## Bonus\n",
    "\n",
    "If you have extra time on this lab, go over your code and add error checks for things that might go wrong, such as if the data file does not have the expected format or if an operation returns empty lists. Instead of throwing errors in these situations, your script should print informative error messages (remember `try`/`except` clauses). In addition, you can go over your code to refactor it into potentially re-usable functions. Finally, you can use the ipywidgets we covered in class to make your figures interactive. Do this part on the code above and list all the improments you made in the text here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3FhAAkeiBBrU"
   },
   "source": [
    "## Step 7: Submit your code on Canvas\n",
    "\n",
    "Complete this lab by submitting this file (`lab2.ipynb`) on Canvas, by January 24, 23:59. We will test your code by manually running them and inspecting the code to verify that:\n",
    "* Your face data analysis prints out a clearly stated question and the answer to the question onto the terminal. The code for computing the answer correctly represents the intended question. It also creates an interpretable visualization of parts of the data that would allow a person to answer the same question.\n",
    "* Your step counter code visualizes the accelerometer data, clearly showing times where there is no movement and where peaks and valleys are detected by your algorithm. It prints the detected number of steps on the terminal at the end. The detected number is reasonable compared to ground truth and the code corresponds to the described algorithm.\n",
    "\n",
    "See Canvas for a grading rubric."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
